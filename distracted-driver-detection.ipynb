{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kaggle challenge - State Farm Distracted Driver detection #\n",
    "Nepp & Dumhart\n",
    "\n",
    "\n",
    "## Dataset ##\n",
    "\n",
    "- 102k files ( labeled images of drivers )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_array(array):\n",
    "    if len(array.shape) > 2: # Check whether image is colored\n",
    "        array = cv2.cvtColor(array.astype(\"uint8\"), cv2.COLOR_BGR2RGB) # Swap BGR to RGB\n",
    "    pil_img = Image.fromarray(array)\n",
    "    display(pil_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think we need more data... More space invariance...\n",
    "\n",
    "def augment_data(X_train, y_train):\n",
    "    \"\"\"ONLY FOR TRAINING DATA. Generate synthetic images by simple transformations. \n",
    "    Size is the number of samples to be returned.  If size is set to zero, the same number \n",
    "    as input images is returned.\"\"\"\n",
    "    \n",
    "    size = X_train.shape[0]\n",
    "    assert X_train.shape[0] == y_train.shape[0]\n",
    "    \n",
    "    # Convert images to 2D\n",
    "    images = X_train#[image.reshape(image_shape) for image in X_train]\n",
    "    labels = y_train\n",
    " \n",
    "    # Create augmented images equal to size\n",
    "    augmented_images = []\n",
    "    new_labels = []\n",
    "    for i in range(size):\n",
    "        augmented_images.append(images[i])\n",
    "        new_labels.append(labels[i])\n",
    "        for ii in range(3):\n",
    "            #--- \n",
    "            img = images[i]\n",
    "            # Rotate image with random parameters\n",
    "            rows,cols = img.shape[:2]\n",
    "            rot_matrix = cv2.getRotationMatrix2D(center=(cols/2, rows/2), \n",
    "                                                 angle=np.random.randint(-25, 25), \n",
    "                                                 scale=1)\n",
    "            img = cv2.warpAffine(img, rot_matrix, (cols,rows))\n",
    "            # Add augmented image and corresponding labels to result containers\n",
    "            augmented_images.append(img)\n",
    "            new_labels.append(labels[i])\n",
    "            #---\n",
    " \n",
    "    return np.array(augmented_images), np.array(new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preprocessing : ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 96)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-87f8b8d4ed0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m307200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'[ 0.          2.00787402  4.01574803 ... 18.07086614  4.01574803\\n  0.        ]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/imgs/test/img_2.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def normalize_image(image) :\n",
    "    image = image / image.max()\n",
    "    #image /= 255.0\n",
    "    return image\n",
    " \n",
    "def line_detection( image ) :\n",
    "        # Creating a custom line filter :\n",
    "    line_filter = np.array([[-1, -2, -1], \n",
    "                            [ 0,  0,  0], \n",
    "                            [ 1,  2,  1]])\n",
    "    stage_1 = ((cv2.filter2D(image, -1, line_filter) + cv2.filter2D(image, -1, line_filter.T))/2).astype(np.uint8)\n",
    "    \n",
    "    # New mirrored line filter :\n",
    "    line_filter = np.array([[  1,   2,   1], \n",
    "                            [  0,   0,   0], \n",
    "                            [ -1,  -2,  -1]])\n",
    "    stage_2 = ((cv2.filter2D(image, -1, line_filter) + cv2.filter2D(image, -1, line_filter.T))/2).astype(np.uint8)\n",
    "    \n",
    "    return np.maximum(stage_1,stage_2).astype(np.uint8)\n",
    "\n",
    "def greyed_blured_and_line_detection( image, advanced=False, do_line_detection=True ) :\n",
    "    # Remove color :\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Blur :\n",
    "    if do_line_detection : blured = cv2.GaussianBlur(image,(5, 5), 0)\n",
    "    \n",
    "    if not advanced or not do_line_detection :\n",
    "        if do_line_detection: return line_detection(blured)\n",
    "        else : return image\n",
    "    else :\n",
    "        image = line_detection( image )\n",
    "        blured = line_detection( blured )\n",
    "        very_blured = cv2.GaussianBlur(image,(11, 11), 0)\n",
    "        return  np.maximum(\n",
    "                line_detection(very_blured), \n",
    "                np.maximum(image,blured).astype(np.uint8)).astype(np.uint8)\n",
    "\n",
    "        #np.maximum(image,blured).astype(np.uint8)\n",
    "    \n",
    "   \n",
    "def preprocess_image(img, advanced=False, do_line_detection=True, image_shape=None, flatten=True) :\n",
    "    img = greyed_blured_and_line_detection(img, advanced=advanced, do_line_detection=do_line_detection)\n",
    "    img = normalize_image(img)\n",
    "    #print('After norm :',img)\n",
    "    if image_shape is not None : img = cv2.resize(img,(image_shape[1],image_shape[0]))\n",
    "    #print('After resize :', img)\n",
    "    if flatten : img = img.flatten()\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "test_img = cv2.imread(\"data/imgs/test/img_2.jpg\")\n",
    "test_img = preprocess_image(test_img, image_shape=(128, 96), flatten=False)\n",
    "print(test_img.shape)\n",
    "\n",
    "# Let's test the preprocessing suite first :  \n",
    "test_img = cv2.imread(\"data/imgs/test/img_2.jpg\")\n",
    "test_img = preprocess_image(test_img)\n",
    "assert test_img.shape == (307200,)\n",
    "assert str(test_img) == '[ 0.          2.00787402  4.01574803 ... 18.07086614  4.01574803\\n  0.        ]'\n",
    "test_img = cv2.imread(\"data/imgs/test/img_2.jpg\")\n",
    "test_img = preprocess_image(test_img, flatten=False)\n",
    "assert test_img.shape == (480, 640) \n",
    "del test_img\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "print(cv2.imread(\"data/imgs/test/img_1.jpg\").shape)\n",
    "    \n",
    "# Converting to grayscale\n",
    "display_array(\n",
    "    cv2.resize(\n",
    "    greyed_blured_and_line_detection( \n",
    "        cv2.imread(\"data/imgs/test/img_1.jpg\"), advanced=False\n",
    "    ),(128, 96))\n",
    ")\n",
    "display_array(\n",
    "    cv2.resize(\n",
    "    greyed_blured_and_line_detection( \n",
    "        cv2.imread(\"data/imgs/test/img_1.jpg\"), advanced=True\n",
    "    ),(128, 96))\n",
    ")\n",
    "display_array(\n",
    "    cv2.resize(\n",
    "    greyed_blured_and_line_detection( \n",
    "        cv2.imread(\"data/imgs/test/img_1.jpg\"), advanced=True, do_line_detection=False\n",
    "    ),(128, 96))\n",
    ")\n",
    "display_array(\n",
    "    greyed_blured_and_line_detection( \n",
    "        cv2.imread(\"data/imgs/test/img_1.jpg\"), advanced=True\n",
    "    )\n",
    ")\n",
    "  \n",
    "display_array(\n",
    "    cv2.imread(\"data/imgs/test/img_1.jpg\") \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Batch Reading : ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "\n",
    "# This method returns the number of files at a given relative path.\n",
    "def files_in_dir(file_path) :\n",
    "    # simple version for working with CWD \n",
    "    # https://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python\n",
    "    return len([name for name in os.listdir(file_path)]) \n",
    "\n",
    "assert files_in_dir(\"./data/imgs/test/\") == 79726\n",
    "\n",
    "# This method generates a ditionary of class names and the number of instances.\n",
    "def create_class_data_map(path) :\n",
    "    \n",
    "    directories = os.listdir(path)\n",
    "    \n",
    "    class_data_map = dict()\n",
    "    \n",
    "    for c in directories : \n",
    "        class_data_map[c] = files_in_dir(path+\"/\"+c)\n",
    "        \n",
    "    return class_data_map\n",
    "    \n",
    "# Testing the above :  \n",
    "assert str(create_class_data_map(\"./data/imgs/\")) == \"{'test': 79726, 'train': 10}\"\n",
    "\n",
    "# This method is currently not used. It takes percentage chunks from a provided\n",
    "# \"class_data_map\" generated by the method above.\n",
    "def create_class_data_picks(class_data_map, percentage) :\n",
    "    \n",
    "    if percentage is None : return class_data_map\n",
    "    \n",
    "    assert percentage <= 1 and percentage >= 0\n",
    "    \n",
    "    # https://w3resource.com/python-exercises/dictionary/python-data-type-dictionary-exercise-15.php\n",
    "    key_min = min(class_data_map.keys(), key=(lambda k: class_data_map[k]))\n",
    "    print('Min Value: ',class_data_map[key_min])\n",
    "    \n",
    "    temp = dict()\n",
    "    for c, d in class_data_map.items(): temp[c] = int(class_data_map[key_min] * percentage)\n",
    "        \n",
    "    return temp\n",
    "        \n",
    "def norm(data, norm_type) :\n",
    "    if norm_type == 'default' :\n",
    "        return data / 255\n",
    "    elif norm_type == 'mean_remove' : \n",
    "        return data - np.mean(data)\n",
    "    elif norm_type == 'standard' :\n",
    "        return ( data - np.mean(data) ) / np.std(data)\n",
    "    elif norm_type == 'softmax' :\n",
    "        e_x = np.exp(data - np.max(data))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    return data\n",
    "\n",
    " \n",
    "    \n",
    "def load_batch( \n",
    "    path, \n",
    "    class_picks, \n",
    "    size, \n",
    "    index, \n",
    "    do_label_index_encoding=False, \n",
    "    advanced_preprocessing=False,\n",
    "    do_line_detection=True,\n",
    "    image_shape=None,\n",
    "    flatten=True,\n",
    "    normalization=None\n",
    ") : \n",
    "    print('Batch loading now..., size=',size,)\n",
    "    #print(\"path='\",path,\"', class_picks='\",class_picks,\"', size='\",size,\"', index='\",index,\"'\")\n",
    "    #print(\"do_label_index_encoding=\",do_label_index_encoding,\", advanced_preprocessing=\",advanced_preprocessing,\",\")\n",
    "    #print(\"image_shape=\",image_shape,\", flatten=\",flatten,\", normalization=\",normalization)\n",
    "    batch = []\n",
    "    labels = []\n",
    "    class_list = list(class_picks.keys())\n",
    "    \n",
    "    read_checker = {c:-size*index for c in class_list}\n",
    "    \n",
    "    imgs_list = pd.read_csv(\"data/driver_imgs_list.csv\")\n",
    "     \n",
    "    for i, row in imgs_list.iterrows():\n",
    "        \n",
    "        c = row['classname']\n",
    "        \n",
    "        if read_checker[c] < 0 : read_checker[c] += 1\n",
    "        elif read_checker[c] < size :\n",
    "            #print('Loading class : \"',c,'\"; Already read :', read_checker[c])\n",
    "            read_checker[c] += 1\n",
    "            name = row['img']\n",
    "            img = cv2.imread(path+\"/\"+c+\"/\"+name)\n",
    "            img = preprocess_image(\n",
    "                img, \n",
    "                advanced=advanced_preprocessing,\n",
    "                do_line_detection=do_line_detection,\n",
    "                image_shape=image_shape,\n",
    "                flatten=flatten\n",
    "            ) \n",
    "            img = norm(img, normalization)\n",
    "            \n",
    "            label = None\n",
    "            label_index = class_list.index(c)\n",
    "            if do_label_index_encoding :\n",
    "                label = label_index\n",
    "            else :\n",
    "                label = [0]*len(class_list)\n",
    "                label[label_index] = 1\n",
    "                label = np.array(label)\n",
    "            #print('Appending : B->',img.shape,'; L->',label.shape)\n",
    "            batch.append(img)\n",
    "            labels.append(label)\n",
    "                 \n",
    "    batch = np.stack(batch)\n",
    "    labels = np.stack(labels)\n",
    "    print(batch.shape, labels.shape)\n",
    "    if not flatten :\n",
    "        batch, labels = augment_data(batch, labels)\n",
    "    print(batch.shape, labels.shape)\n",
    "    print('Batch loaded! : batch.shape=',batch.shape,'; labels.shape=',labels.shape,';')\n",
    "    return batch, labels\n",
    "    \n",
    "     \n",
    "b, l = load_batch(\n",
    "    \"data/imgs/train\", \n",
    "    create_class_data_map(\"data/imgs/train\"),\n",
    "    size=6, index=0\n",
    ") \n",
    "    \n",
    "assert b.shape == (60, 307200)\n",
    "assert l.shape == (60, 10)  \n",
    "\n",
    "b, l = load_batch(\n",
    "    \"data/imgs/train\", \n",
    "    create_class_data_map(\"data/imgs/train\"),\n",
    "    size=6, index=0, do_label_index_encoding=True\n",
    ")\n",
    "\n",
    "\n",
    "assert b.shape == (60, 307200)\n",
    "assert l.shape == (60,)\n",
    "    \n",
    "b, l = load_batch(\n",
    "    \"data/imgs/train\", \n",
    "    create_class_data_map(\"data/imgs/train\"),\n",
    "    size=6, index=0, do_label_index_encoding=True, flatten=False\n",
    ")\n",
    " \n",
    "assert b.shape == (60, 480, 640)\n",
    "assert l.shape == (60,)\n",
    "\n",
    "b, l = load_batch(\n",
    "    \"data/imgs/train\", \n",
    "    create_class_data_map(\"data/imgs/train\"),\n",
    "    size=6, index=0, do_label_index_encoding=True, flatten=False,\n",
    "    image_shape=(128, 96)\n",
    ")\n",
    " \n",
    "assert b.shape == (60, 128, 96)\n",
    "assert l.shape == (60,)\n",
    "     \n",
    "del b, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "\n",
    "def mish(x): return x * (K.tanh(K.softplus(x)))\n",
    "get_custom_objects().update({'mish': Activation(mish)})\n",
    "\n",
    "def exec_trial(settings) :\n",
    "    \n",
    "    print('Starting trial with the following parameters : \\n', settings)\n",
    "    # Read settings:\n",
    "    advanced_preprocessing = settings['advanced_preprocessing']\n",
    "    do_conv = settings['convos'] != None\n",
    "    flatten = not do_conv\n",
    "    actifuns = settings['actifuns']\n",
    "    layer_sizes = settings['layer_sizes']\n",
    "    batch_size = settings['batch_size'] #:= 50\n",
    "    normalization = settings['normalization']\n",
    "    \n",
    "\n",
    "    # Loading (and preprocessing) data :\n",
    "    train_batch, train_labels = load_batch(\n",
    "        \"data/imgs/train\", \n",
    "        create_class_data_map(\"data/imgs/train\"), \n",
    "        size=batch_size, \n",
    "        index=0, \n",
    "        #do_label_index_encoding=True, # This is too much for the NN\n",
    "        advanced_preprocessing=advanced_preprocessing,\n",
    "        image_shape=(96, 96),#(256, 192) #640 * 480\n",
    "        flatten=flatten,\n",
    "        normalization=normalization\n",
    "    )\n",
    "    \n",
    "    print('Input shape :', train_batch.shape, '; flatten : ', flatten, '; do_conv :', do_conv)\n",
    "    print('Label shape :',train_labels.shape)\n",
    "    # reshape for convolution:\n",
    "    if do_conv : \n",
    "        train_batch = train_batch.reshape(list(train_batch.shape) + [1]) \n",
    "        print('Input shape for convolution:', train_batch.shape)\n",
    "         \n",
    "    input_dimension = train_batch.shape[1]\n",
    "    input_shape = train_batch.shape\n",
    "    output_dimension = 10#train_labels.shape[len(train_labels.shape)-1]\n",
    "\n",
    "    print('Input dimension:',input_dimension,'; output_dimension:',output_dimension,';')\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    if 'mish' in actifuns: model.add(Activation(mish, name='mish'))\n",
    "    #---------------------------------------\n",
    " \n",
    "    # CONVOLUTION ... WIP\n",
    "    if do_conv :\n",
    "        first_iter_done = False\n",
    "        for convo in settings['convos'] : \n",
    "            value = convo['value']\n",
    "            if convo['type'] == 'conv2d' : \n",
    "                if first_iter_done :\n",
    "                    model.add(\n",
    "                        keras.layers.Conv2D(\n",
    "                            value['filters'], \n",
    "                            value['kernel_size'],  \n",
    "                            activation=value['activation'],  \n",
    "                            padding=value['padding']\n",
    "                        )\n",
    "                    )\n",
    "                else :\n",
    "                    model.add(\n",
    "                        keras.layers.Conv2D(\n",
    "                            value['filters'], \n",
    "                            value['kernel_size'], \n",
    "                            input_shape=(96, 96, 1),\n",
    "                            activation=value['activation'],  \n",
    "                            padding=value['padding']\n",
    "                        )\n",
    "                    )\n",
    "            elif convo['type'] == 'maxpool' : \n",
    "                model.add(keras.layers.MaxPooling2D(pool_size=convo['value']['pool_size']))\n",
    "            elif convo['type'] == 'avgpool' :\n",
    "                model.add(keras.layers.AveragePooling2D(pool_size=convo['value']['pool_size']))\n",
    "            else : print('Invalid configuration!!! Convolution type \"', convo['type'],'\" unknown!')\n",
    "            first_iter_done = True\n",
    "            model.add(keras.layers.Dropout(0.1))\n",
    "        \n",
    "        model.add(keras.layers.Flatten())\n",
    "        start = 0\n",
    "    else :  \n",
    "        model.add(keras.layers.Dense(layer_sizes[0], input_dim=input_dimension, activation=actifuns[0]))\n",
    "        start = 1\n",
    "    \n",
    "    for i in range(start, len(layer_sizes)) :\n",
    "        print('Adding layer', i, 'with size ', layer_sizes[i], 'and activation', actifuns[i])\n",
    "        model.add(keras.layers.Dense(layer_sizes[i], activation=actifuns[i]))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "        \n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            output_dimension, \n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    model.build(input_shape=train_batch.shape)\n",
    "\n",
    "    # Create model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"categorical_crossentropy\",#\"categorical_crossentropy\"\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    print(model.summary())\n",
    "    #plot_model(model)\n",
    "    \n",
    "    print('-----------------------------------------------------\\nTraining now...')\n",
    "    print('train_labels.shape=',train_labels.shape)\n",
    "    print('train_batch.shape=',train_batch.shape)\n",
    "    print('input_dimension=',input_dimension)\n",
    "    print('output_dimension=',output_dimension)\n",
    "    \n",
    "    # Configure stopping criterion via early stopping\n",
    "    # callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=4)\n",
    "\n",
    "    # Train model\n",
    "    history_augmented = model.fit(\n",
    "        train_batch, \n",
    "        train_labels,\n",
    "        validation_split=0.2,\n",
    "        epochs=10,\n",
    "        #callbacks=[callback],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    X_test, y_test = load_batch(\n",
    "        \"data/imgs/train\", \n",
    "        create_class_data_map(\"data/imgs/train\"), \n",
    "        size=batch_size, \n",
    "        index=1, \n",
    "        #do_label_index_encoding=True,\n",
    "        advanced_preprocessing=advanced_preprocessing,\n",
    "        image_shape=(96, 96),#(128, 96) #640 * 480\n",
    "        flatten=flatten,\n",
    "        normalization=normalization\n",
    "    ) \n",
    "    print(X_test.shape)\n",
    "        # reshape for convolution:\n",
    "    if do_conv : \n",
    "        X_test = X_test.reshape(list(X_test.shape) + [1]) \n",
    "        print('Input shape for convolution:', train_batch.shape)\n",
    "         \n",
    "    print(X_test.shape)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print('Done! Test-loss:', test_loss, '; Test-acc', test_acc, ';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some hyperparameter tuning : ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial with the following parameters : \n",
      " {'do_line_detection': True, 'advanced_preprocessing': True, 'normalization': 'standard', 'actifuns': ['mish', 'mish', 'mish'], 'layer_sizes': [], 'batch_size': 300, 'convos': [{'type': 'conv2d', 'value': {'filters': 16, 'kernel_size': (3, 3), 'activation': 'selu', 'padding': 'same'}}, {'type': 'maxpool', 'value': {'pool_size': (3, 3)}}, {'type': 'conv2d', 'value': {'filters': 128, 'kernel_size': (3, 3), 'activation': 'selu', 'padding': 'same'}}, {'type': 'maxpool', 'value': {'pool_size': (3, 3)}}, {'type': 'conv2d', 'value': {'filters': 128, 'kernel_size': (3, 3), 'activation': 'selu', 'padding': 'same'}}, {'type': 'maxpool', 'value': {'pool_size': (3, 3)}}]}\n",
      "Batch loading now..., size= 300\n",
      "(3000, 96, 96) (3000, 10)\n",
      "(12000, 96, 96) (12000, 10)\n",
      "Batch loaded! : batch.shape= (12000, 96, 96) ; labels.shape= (12000, 10) ;\n",
      "Input shape : (12000, 96, 96) ; flatten :  False ; do_conv : True\n",
      "Label shape : (12000, 10)\n",
      "Input shape for convolution: (12000, 96, 96, 1)\n",
      "Input dimension: 96 ; output_dimension: 10 ;\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mish (Activation)            (12000, 96, 96, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (12000, 96, 96, 16)       160       \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (12000, 96, 96, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (12000, 32, 32, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (12000, 32, 32, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (12000, 32, 32, 128)      18560     \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (12000, 32, 32, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (12000, 10, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (12000, 10, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (12000, 10, 10, 128)      147584    \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (12000, 10, 10, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (12000, 3, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (12000, 3, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (12000, 1152)             0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (12000, 10)               11530     \n",
      "=================================================================\n",
      "Total params: 177,834\n",
      "Trainable params: 177,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "-----------------------------------------------------\n",
      "Training now...\n",
      "train_labels.shape= (12000, 10)\n",
      "train_batch.shape= (12000, 96, 96, 1)\n",
      "input_dimension= 96\n",
      "output_dimension= 10\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 49s 162ms/step - loss: 2.1607 - accuracy: 0.2349 - val_loss: 2.4952 - val_accuracy: 0.1642\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 50s 166ms/step - loss: 1.4681 - accuracy: 0.5566 - val_loss: 2.7393 - val_accuracy: 0.2387\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.7864 - accuracy: 0.7676 - val_loss: 2.7359 - val_accuracy: 0.3492\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.4898 - accuracy: 0.8577 - val_loss: 3.0881 - val_accuracy: 0.3363\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 47s 158ms/step - loss: 0.3347 - accuracy: 0.9042 - val_loss: 2.9352 - val_accuracy: 0.3896\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 48s 159ms/step - loss: 0.2609 - accuracy: 0.9247 - val_loss: 3.0246 - val_accuracy: 0.3567\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 48s 159ms/step - loss: 0.2073 - accuracy: 0.9383 - val_loss: 3.0279 - val_accuracy: 0.3692\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 50s 165ms/step - loss: 0.1704 - accuracy: 0.9491 - val_loss: 3.0978 - val_accuracy: 0.3454\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 50s 166ms/step - loss: 0.1395 - accuracy: 0.9592 - val_loss: 3.3684 - val_accuracy: 0.3779\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 47s 158ms/step - loss: 0.1117 - accuracy: 0.9680 - val_loss: 3.4104 - val_accuracy: 0.3562\n",
      "Batch loading now..., size= 300\n",
      "(3000, 96, 96) (3000, 10)\n",
      "(12000, 96, 96) (12000, 10)\n",
      "Batch loaded! : batch.shape= (12000, 96, 96) ; labels.shape= (12000, 10) ;\n",
      "(12000, 96, 96)\n",
      "Input shape for convolution: (12000, 96, 96, 1)\n",
      "(12000, 96, 96, 1)\n",
      " 80/375 [=====>........................] - ETA: 9s - loss: 3.9339 - accuracy: 0.3121"
     ]
    }
   ],
   "source": [
    "trials = [\n",
    "    {\n",
    "        'do_line_detection':True,\n",
    "        'advanced_preprocessing':True,\n",
    "        'normalization':'standard',\n",
    "        'actifuns' : ['mish', 'mish', 'mish'],\n",
    "        'layer_sizes' : [],\n",
    "        'batch_size' : 300,\n",
    "        'convos' : [ #64, (8,8), input_shape=(128, 96, 1),activation=hidden_acti,  padding=\"same\"\n",
    "            {\n",
    "                'type':'conv2d', #128, (8, 8), activation=\"selu\", padding=\"same\"\n",
    "                'value' : {\n",
    "                    'filters': 16,\n",
    "                    \"kernel_size\": (3,3),\n",
    "                    \"activation\" : \"selu\",\n",
    "                    \"padding\": \"same\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type':'maxpool', \n",
    "                'value' : {\n",
    "                    'pool_size': (3,3)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type':'conv2d', #128, (8, 8), activation=\"selu\", padding=\"same\"\n",
    "                'value' : {\n",
    "                    'filters': 128,\n",
    "                    \"kernel_size\": (3,3),\n",
    "                    \"activation\" : \"selu\",\n",
    "                    \"padding\": \"same\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type':'maxpool', \n",
    "                'value' : {\n",
    "                    'pool_size': (3,3)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type':'conv2d', \n",
    "                'value' : {\n",
    "                    'filters': 128,\n",
    "                    \"kernel_size\": (3,3),\n",
    "                    \"activation\" : \"selu\",\n",
    "                    \"padding\": \"same\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type':'maxpool', \n",
    "                'value' : {\n",
    "                    'pool_size': (3,3)\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'do_line_detection':True,\n",
    "        'advanced_preprocessing':True,\n",
    "        'normalization':'standard',\n",
    "        'actifuns' : ['mish', 'mish', 'mish', 'mish', 'mish', 'mish'],\n",
    "        'layer_sizes' : [1024, 512, 256, 64, 64, 64],\n",
    "        'batch_size' : 190,\n",
    "        'convos' : None\n",
    "    }\n",
    "]\n",
    "   \n",
    "for trial in trials : exec_trial(trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result accuracy:',test_acc*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
